{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1oFPRakdoSyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qu5Bbcezpup4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "dataset_path = os.listdir('/content/drive/MyDrive/Dataset Folder')\n",
        "\n",
        "print (dataset_path)  #the classes in this dataset are the file names\n",
        "\n",
        "print(\"Types of classes labels found: \", len(dataset_path))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = []\n",
        "\n",
        "for item in dataset_path:\n",
        " # Get all the file names\n",
        " all_classes = os.listdir('/content/drive/MyDrive/Dataset Folder' + '/' +item)\n",
        " #print(all_classes)\n",
        "\n",
        " # Add them to the list\n",
        " for room in all_classes:\n",
        "    class_labels.append((item, str('dataset_path' + '/' +item) + '/' + room))"
      ],
      "metadata": {
        "id": "6de6Lat2WSl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a dataframe\n",
        "df = pd.DataFrame(data=class_labels, columns=['Labels', 'image'])\n",
        "print(df.head())\n",
        "print(df.tail())"
      ],
      "metadata": {
        "id": "uC2CMU8MXm8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total number of images in the dataset: \", len(df))\n",
        "\n",
        "label_count = df['Labels'].value_counts()\n",
        "print(label_count)"
      ],
      "metadata": {
        "id": "_-pFYeDbXuyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "path = '/content/drive/MyDrive/Dataset Folder/'\n",
        "dataset_path = os.listdir('/content/drive/MyDrive/Dataset Folder')\n",
        "\n",
        "im_size = 600\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for i in dataset_path:\n",
        "    data_path = path + str(i)\n",
        "    filenames = [i for i in os.listdir(data_path) ]\n",
        "\n",
        "    for f in filenames:\n",
        "        img = cv2.imread(data_path + '/' + f)\n",
        "        img = cv2.resize(img, (im_size, im_size))\n",
        "        images.append(img)\n",
        "        labels.append(i)"
      ],
      "metadata": {
        "id": "9A6BhoasX4-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This model takes input images of shape (600, 600, 3), and the input data should range [0, 255].\n",
        "\n",
        "images = np.array(images)\n",
        "\n",
        "images = images.astype('float32') / 255.0\n",
        "images.shape"
      ],
      "metadata": {
        "id": "N5PbUv8xYpKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
        "y=df['Labels'].values\n",
        "print(y)\n",
        "\n",
        "y_labelencoder = LabelEncoder ()\n",
        "y = y_labelencoder.fit_transform (y)\n",
        "print (y)"
      ],
      "metadata": {
        "id": "AdZVKPBmZSa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=y.reshape(-1,1)\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "ct = ColumnTransformer([('my_ohe', OneHotEncoder(), [0])], remainder='passthrough')\n",
        "Y = ct.fit_transform(y)\n",
        "print(Y[:5])\n",
        "print(Y[35:])"
      ],
      "metadata": {
        "id": "1YTzALAuZWoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "images, Y = shuffle(images, Y, random_state=1)\n",
        "\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(images, Y, test_size=0.05, random_state=415)\n",
        "\n",
        "#inpect the shape of the training and testing.\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n",
        "print(test_x.shape)\n",
        "print(test_y.shape)\n",
        "print(train_y.dtype)\n",
        "train_y = train_y.toarray()\n",
        "train_y = tf.cast(train_y, tf.int32)\n",
        "print(train_y.dtype)"
      ],
      "metadata": {
        "id": "woiC_FTpZ8X_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import EfficientNetB7\n",
        "\n",
        "NUM_CLASSES = 6\n",
        "IMG_SIZE = 600\n",
        "size = (IMG_SIZE, IMG_SIZE)\n",
        "\n",
        "\n",
        "inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "outputs = EfficientNetB7(include_top=True, weights=None, classes=NUM_CLASSES)(inputs)"
      ],
      "metadata": {
        "id": "8ZfbIUqOaQ9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "#model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"] )\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"] )\n",
        "\n",
        "model.summary()\n",
        "\n",
        "hist = model.fit(train_x, train_y, epochs=10, verbose=2)"
      ],
      "metadata": {
        "id": "61szaRcHatNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_hist(hist):\n",
        "    plt.plot(hist.history[\"accuracy\"])\n",
        "    #plt.plot(hist.history[\"val_accuracy\"])\n",
        "    plt.title(\"model accuracy\")\n",
        "    plt.ylabel(\"accuracy\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_hist(hist)"
      ],
      "metadata": {
        "id": "wLDlKpWYa5Ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.evaluate(test_x, test_y)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ],
      "metadata": {
        "id": "RlySGPgmbBlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions for the test set\n",
        "predictions = model.predict(test_x)\n",
        "\n",
        "# Convert predicted labels from one-hot encoding to class labels\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Convert true labels from one-hot encoding to class labels\n",
        "true_labels = np.argmax(test_y, axis=1)\n",
        "\n",
        "# Calculate mean average accuracy\n",
        "maa = mean_average_accuracy(true_labels, predicted_labels)\n",
        "print(\"Mean Average Accuracy:\", maa)"
      ],
      "metadata": {
        "id": "EMKeJlwGbEoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yLwHVrA2nq4T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}